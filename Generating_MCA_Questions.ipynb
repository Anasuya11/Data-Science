{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpo9QXNNACWxIJCxmOMWH4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anasuya11/DS-Tasks/blob/main/Generating_MCA_Questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import random\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a given PDF.\"\"\"\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def generate_mca_from_paragraph(paragraph):\n",
        "    doc = nlp(paragraph)\n",
        "\n",
        "    # Extract main verbs, which often carry the main action or idea in a sentence\n",
        "    main_verbs = [token for token in doc if \"VERB\" in token.pos_ and token.dep_ == \"ROOT\"]\n",
        "    if not main_verbs:\n",
        "        return None\n",
        "\n",
        "    main_verb = random.choice(main_verbs)\n",
        "    subj = [child for child in main_verb.children if \"subj\" in child.dep_]\n",
        "    obj = [child for child in main_verb.children if \"obj\" in child.dep_]\n",
        "    if not subj or not obj:\n",
        "        return None\n",
        "\n",
        "    question = f\"What did {subj[0].text} {main_verb.lemma_} in the context?\"\n",
        "    correct_choices = [obj[0].text]\n",
        "\n",
        "    # Add another relevant entity/keyword from the sentence as a correct choice\n",
        "    relevant_terms = [token.text for token in doc if token.pos_ in ['NOUN', 'PROPN'] and token.text not in correct_choices]\n",
        "    if relevant_terms:\n",
        "        correct_choices.append(random.choice(relevant_terms))\n",
        "\n",
        "    distractors = [ent.text for ent in doc.ents if ent.text not in correct_choices]\n",
        "\n",
        "    # Ensure we have at least two distractors to make up the 4 options\n",
        "    if len(distractors) < 2:\n",
        "        return None\n",
        "\n",
        "    # Adjust the code here to make sure we have a total of 4 choices\n",
        "    all_choices = correct_choices + random.sample(distractors, 4 - len(correct_choices))\n",
        "    random.shuffle(all_choices)\n",
        "\n",
        "    return question, all_choices, correct_choices\n",
        "\n",
        "\n",
        "def extract_questions_from_text(text):\n",
        "    paragraphs = [p for p in text.split(\"\\n\") if p]\n",
        "    questions = []\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        mca_data = generate_mca_from_paragraph(paragraph)\n",
        "        if mca_data:\n",
        "            questions.append(mca_data)\n",
        "\n",
        "    return questions\n",
        "\n",
        "pdf_files = [\"/content/internship-assignment-nlp/Dataset/chapter-2.pdf\", \"/content/internship-assignment-nlp/Dataset/chapter-3.pdf\", \"/content/internship-assignment-nlp/Dataset/chapter-4.pdf\"]\n",
        "\n",
        "all_questions = []\n",
        "for pdf_file in pdf_files:\n",
        "    text = extract_text_from_pdf(pdf_file)\n",
        "    questions = extract_questions_from_text(text)\n",
        "    all_questions.extend(questions)\n",
        "\n",
        "for idx, (q, options, correct) in enumerate(all_questions, 1):\n",
        "    print(f\"Q{idx}: {q}\")\n",
        "    for i, option in enumerate(options, 1):\n",
        "        print(f\"{i}. {option}\")\n",
        "    correct_indices = [str(options.index(c) + 1) for c in correct]\n",
        "    print(f\"Correct Answers: {', '.join(correct_indices)}\\n\")\n"
      ],
      "metadata": {
        "id": "ClonpsCU1Skt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}